{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import filter_env\n",
    "from ou_noise import OUNoise\n",
    "from replay_buffer import ReplayBuffer\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters/Settings\n",
    "ENV_NAME = 'Pendulum-v0' #'InvertedPendulum-v1'\n",
    "EPISODES = 100000\n",
    "TEST = 10\n",
    "\n",
    "LAYER1_SIZE = 400\n",
    "LAYER2_SIZE = 300\n",
    "LEARNING_RATE = 1e-4\n",
    "TAU = 0.001\n",
    "BATCH_SIZE = 32 #64\n",
    "\n",
    "REPLAY_BUFFER_SIZE = 1000000\n",
    "REPLAY_START_SIZE = 100 #10000\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActorCriticNet(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(ActorCriticNet, self).__init__()\n",
    "\n",
    "        self.actor = ActorNet(state_dim, action_dim)\n",
    "        self.critic = CriticNet(state_dim, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        action = self.actor(state)\n",
    "        value = self.critic(state, action)\n",
    "        return value, action\n",
    "\n",
    "    def getAction(self, state):\n",
    "        return self.actor(state)\n",
    "\n",
    "    def getValue(self, state, action=None):\n",
    "        if action is None:\n",
    "            return self.critic(state, self.actor(state))\n",
    "        return self.critic(state, action)\n",
    "\n",
    "    def train(self): # might not be necessary\n",
    "        self.critic.train()\n",
    "        self.actor.train()\n",
    "        super(ActorCriticNet, self).train()\n",
    "    \n",
    "    def eval(self): # might not be necessary\n",
    "        self.critic.eval()\n",
    "        self.actor.eval()\n",
    "        super(ActorCriticNet, self).eval()\n",
    "\n",
    "class CriticNet(nn.Module):\n",
    "\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(CriticNet, self).__init__()\n",
    "\n",
    "        # make sure all params are initizialized randomly [-1/np.sqrt(dim),1/np.sqrt(dim)]\n",
    "        self.layer1 = nn.Linear(state_dim,LAYER1_SIZE)\n",
    "        self.action_layer = nn.Linear(action_dim,LAYER2_SIZE,bias=False)\n",
    "        self.layer2 = nn.Linear(LAYER1_SIZE,LAYER2_SIZE)\n",
    "        self.output_layer = nn.Linear(LAYER2_SIZE,1)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x = F.relu(self.layer1(state))\n",
    "        x = F.relu(self.action_layer(action) + self.layer2(x))\n",
    "        q = self.output_layer(x)\n",
    "        return q # predicted q value of this state-action pair\n",
    "\n",
    "class ActorNet(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(ActorNet, self).__init__()\n",
    "\n",
    "        # make sure all params are initizialized randomly [-1/np.sqrt(dim),1/np.sqrt(dim)]\n",
    "        self.layer0_bn = nn.BatchNorm1d(state_dim)\n",
    "        self.layer1 = nn.Linear(state_dim,LAYER1_SIZE)\n",
    "        self.layer1_bn = nn.BatchNorm1d(LAYER1_SIZE)\n",
    "        self.layer2 = nn.Linear(LAYER1_SIZE,LAYER2_SIZE)\n",
    "        self.layer2_bn = nn.BatchNorm1d(LAYER2_SIZE)\n",
    "        self.output_layer = nn.Linear(LAYER2_SIZE,action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.layer0_bn(state))\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(self.layer1_bn(x))\n",
    "        x = self.layer2(x)\n",
    "        x = F.relu(self.layer2_bn(x))\n",
    "        action = F.tanh(self.output_layer(x))\n",
    "        return action # predicted best actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\n",
      "0 a <class 'torch.FloatTensor'>\n",
      "0 s <class 'torch.FloatTensor'>\n",
      "1 a <class 'torch.FloatTensor'>\n",
      "1 s <class 'torch.FloatTensor'>\n",
      "2 a <class 'torch.FloatTensor'>\n",
      "2 s <class 'torch.FloatTensor'>\n",
      "3 a <class 'torch.FloatTensor'>\n",
      "3 s <class 'torch.FloatTensor'>\n",
      "4 a <class 'torch.FloatTensor'>\n",
      "4 s <class 'torch.FloatTensor'>\n",
      "5 a <class 'torch.FloatTensor'>\n",
      "5 s <class 'torch.FloatTensor'>\n",
      "6 a <class 'torch.FloatTensor'>\n",
      "6 s <class 'torch.FloatTensor'>\n",
      "7 a <class 'torch.FloatTensor'>\n",
      "7 s <class 'torch.FloatTensor'>\n",
      "8 a <class 'torch.FloatTensor'>\n",
      "8 s <class 'torch.FloatTensor'>\n",
      "9 a <class 'torch.FloatTensor'>\n",
      "9 s <class 'torch.FloatTensor'>\n",
      "10 a <class 'torch.FloatTensor'>\n",
      "10 s <class 'torch.FloatTensor'>\n",
      "11 a <class 'torch.FloatTensor'>\n",
      "11 s <class 'torch.FloatTensor'>\n",
      "12 a <class 'torch.FloatTensor'>\n",
      "12 s <class 'torch.FloatTensor'>\n",
      "13 a <class 'torch.FloatTensor'>\n",
      "13 s <class 'torch.FloatTensor'>\n",
      "14 a <class 'torch.FloatTensor'>\n",
      "14 s <class 'torch.FloatTensor'>\n",
      "15 a <class 'torch.FloatTensor'>\n",
      "15 s <class 'torch.FloatTensor'>\n",
      "16 a <class 'torch.FloatTensor'>\n",
      "16 s <class 'torch.FloatTensor'>\n",
      "17 a <class 'torch.FloatTensor'>\n",
      "17 s <class 'torch.FloatTensor'>\n",
      "18 a <class 'torch.FloatTensor'>\n",
      "18 s <class 'torch.FloatTensor'>\n",
      "19 a <class 'torch.FloatTensor'>\n",
      "19 s <class 'torch.FloatTensor'>\n",
      "20 a <class 'torch.FloatTensor'>\n",
      "20 s <class 'torch.FloatTensor'>\n",
      "21 a <class 'torch.FloatTensor'>\n",
      "21 s <class 'torch.FloatTensor'>\n",
      "22 a <class 'torch.FloatTensor'>\n",
      "22 s <class 'torch.FloatTensor'>\n",
      "23 a <class 'torch.FloatTensor'>\n",
      "23 s <class 'torch.FloatTensor'>\n",
      "24 a <class 'torch.FloatTensor'>\n",
      "24 s <class 'torch.FloatTensor'>\n",
      "25 a <class 'torch.FloatTensor'>\n",
      "25 s <class 'torch.FloatTensor'>\n",
      "26 a <class 'torch.FloatTensor'>\n",
      "26 s <class 'torch.FloatTensor'>\n",
      "27 a <class 'torch.FloatTensor'>\n",
      "27 s <class 'torch.FloatTensor'>\n",
      "28 a <class 'torch.FloatTensor'>\n",
      "28 s <class 'torch.FloatTensor'>\n",
      "29 a <class 'torch.FloatTensor'>\n",
      "29 s <class 'torch.FloatTensor'>\n",
      "30 a <class 'torch.FloatTensor'>\n",
      "30 s <class 'torch.FloatTensor'>\n",
      "31 a <class 'torch.FloatTensor'>\n",
      "31 s <class 'torch.FloatTensor'>\n",
      "32 a <class 'torch.FloatTensor'>\n",
      "32 s <class 'torch.FloatTensor'>\n",
      "33 a <class 'torch.FloatTensor'>\n",
      "33 s <class 'torch.FloatTensor'>\n",
      "34 a <class 'torch.FloatTensor'>\n",
      "34 s <class 'torch.FloatTensor'>\n",
      "35 a <class 'torch.FloatTensor'>\n",
      "35 s <class 'torch.FloatTensor'>\n",
      "36 a <class 'torch.FloatTensor'>\n",
      "36 s <class 'torch.FloatTensor'>\n",
      "37 a <class 'torch.FloatTensor'>\n",
      "37 s <class 'torch.FloatTensor'>\n",
      "38 a <class 'torch.FloatTensor'>\n",
      "38 s <class 'torch.FloatTensor'>\n",
      "39 a <class 'torch.FloatTensor'>\n",
      "39 s <class 'torch.FloatTensor'>\n",
      "40 a <class 'torch.FloatTensor'>\n",
      "40 s <class 'torch.FloatTensor'>\n",
      "41 a <class 'torch.FloatTensor'>\n",
      "41 s <class 'torch.FloatTensor'>\n",
      "42 a <class 'torch.FloatTensor'>\n",
      "42 s <class 'torch.FloatTensor'>\n",
      "43 a <class 'torch.FloatTensor'>\n",
      "43 s <class 'torch.FloatTensor'>\n",
      "44 a <class 'torch.FloatTensor'>\n",
      "44 s <class 'torch.FloatTensor'>\n",
      "45 a <class 'torch.FloatTensor'>\n",
      "45 s <class 'torch.FloatTensor'>\n",
      "46 a <class 'torch.FloatTensor'>\n",
      "46 s <class 'torch.FloatTensor'>\n",
      "47 a <class 'torch.FloatTensor'>\n",
      "47 s <class 'torch.FloatTensor'>\n",
      "48 a <class 'torch.FloatTensor'>\n",
      "48 s <class 'torch.FloatTensor'>\n",
      "49 a <class 'torch.FloatTensor'>\n",
      "49 s <class 'torch.FloatTensor'>\n",
      "50 a <class 'torch.FloatTensor'>\n",
      "50 s <class 'torch.FloatTensor'>\n",
      "51 a <class 'torch.FloatTensor'>\n",
      "51 s <class 'torch.FloatTensor'>\n",
      "52 a <class 'torch.FloatTensor'>\n",
      "52 s <class 'torch.FloatTensor'>\n",
      "53 a <class 'torch.FloatTensor'>\n",
      "53 s <class 'torch.FloatTensor'>\n",
      "54 a <class 'torch.FloatTensor'>\n",
      "54 s <class 'torch.FloatTensor'>\n",
      "55 a <class 'torch.FloatTensor'>\n",
      "55 s <class 'torch.FloatTensor'>\n",
      "56 a <class 'torch.FloatTensor'>\n",
      "56 s <class 'torch.FloatTensor'>\n",
      "57 a <class 'torch.FloatTensor'>\n",
      "57 s <class 'torch.FloatTensor'>\n",
      "58 a <class 'torch.FloatTensor'>\n",
      "58 s <class 'torch.FloatTensor'>\n",
      "59 a <class 'torch.FloatTensor'>\n",
      "59 s <class 'torch.FloatTensor'>\n",
      "60 a <class 'torch.FloatTensor'>\n",
      "60 s <class 'torch.FloatTensor'>\n",
      "61 a <class 'torch.FloatTensor'>\n",
      "61 s <class 'torch.FloatTensor'>\n",
      "62 a <class 'torch.FloatTensor'>\n",
      "62 s <class 'torch.FloatTensor'>\n",
      "63 a <class 'torch.FloatTensor'>\n",
      "63 s <class 'torch.FloatTensor'>\n",
      "64 a <class 'torch.FloatTensor'>\n",
      "64 s <class 'torch.FloatTensor'>\n",
      "65 a <class 'torch.FloatTensor'>\n",
      "65 s <class 'torch.FloatTensor'>\n",
      "66 a <class 'torch.FloatTensor'>\n",
      "66 s <class 'torch.FloatTensor'>\n",
      "67 a <class 'torch.FloatTensor'>\n",
      "67 s <class 'torch.FloatTensor'>\n",
      "68 a <class 'torch.FloatTensor'>\n",
      "68 s <class 'torch.FloatTensor'>\n",
      "69 a <class 'torch.FloatTensor'>\n",
      "69 s <class 'torch.FloatTensor'>\n",
      "70 a <class 'torch.FloatTensor'>\n",
      "70 s <class 'torch.FloatTensor'>\n",
      "71 a <class 'torch.FloatTensor'>\n",
      "71 s <class 'torch.FloatTensor'>\n",
      "72 a <class 'torch.FloatTensor'>\n",
      "72 s <class 'torch.FloatTensor'>\n",
      "73 a <class 'torch.FloatTensor'>\n",
      "73 s <class 'torch.FloatTensor'>\n",
      "74 a <class 'torch.FloatTensor'>\n",
      "74 s <class 'torch.FloatTensor'>\n",
      "75 a <class 'torch.FloatTensor'>\n",
      "75 s <class 'torch.FloatTensor'>\n",
      "76 a <class 'torch.FloatTensor'>\n",
      "76 s <class 'torch.FloatTensor'>\n",
      "77 a <class 'torch.FloatTensor'>\n",
      "77 s <class 'torch.FloatTensor'>\n",
      "78 a <class 'torch.FloatTensor'>\n",
      "78 s <class 'torch.FloatTensor'>\n",
      "79 a <class 'torch.FloatTensor'>\n",
      "79 s <class 'torch.FloatTensor'>\n",
      "80 a <class 'torch.FloatTensor'>\n",
      "80 s <class 'torch.FloatTensor'>\n",
      "81 a <class 'torch.FloatTensor'>\n",
      "81 s <class 'torch.FloatTensor'>\n",
      "82 a <class 'torch.FloatTensor'>\n",
      "82 s <class 'torch.FloatTensor'>\n",
      "83 a <class 'torch.FloatTensor'>\n",
      "83 s <class 'torch.FloatTensor'>\n",
      "84 a <class 'torch.FloatTensor'>\n",
      "84 s <class 'torch.FloatTensor'>\n",
      "85 a <class 'torch.FloatTensor'>\n",
      "85 s <class 'torch.FloatTensor'>\n",
      "86 a <class 'torch.FloatTensor'>\n",
      "86 s <class 'torch.FloatTensor'>\n",
      "87 a <class 'torch.FloatTensor'>\n",
      "87 s <class 'torch.FloatTensor'>\n",
      "88 a <class 'torch.FloatTensor'>\n",
      "88 s <class 'torch.FloatTensor'>\n",
      "89 a <class 'torch.FloatTensor'>\n",
      "89 s <class 'torch.FloatTensor'>\n",
      "90 a <class 'torch.FloatTensor'>\n",
      "90 s <class 'torch.FloatTensor'>\n",
      "91 a <class 'torch.FloatTensor'>\n",
      "91 s <class 'torch.FloatTensor'>\n",
      "92 a <class 'torch.FloatTensor'>\n",
      "92 s <class 'torch.FloatTensor'>\n",
      "93 a <class 'torch.FloatTensor'>\n",
      "93 s <class 'torch.FloatTensor'>\n",
      "94 a <class 'torch.FloatTensor'>\n",
      "94 s <class 'torch.FloatTensor'>\n",
      "95 a <class 'torch.FloatTensor'>\n",
      "95 s <class 'torch.FloatTensor'>\n",
      "96 a <class 'torch.FloatTensor'>\n",
      "96 s <class 'torch.FloatTensor'>\n",
      "97 a <class 'torch.FloatTensor'>\n",
      "97 s <class 'torch.FloatTensor'>\n",
      "98 a <class 'torch.FloatTensor'>\n",
      "98 s <class 'torch.FloatTensor'>\n",
      "99 a <class 'torch.FloatTensor'>\n",
      "99 s <class 'torch.FloatTensor'>\n",
      "100 a <class 'torch.FloatTensor'>\n",
      "100 s <class 'torch.FloatTensor'>\n",
      "[<class 'torch.FloatTensor'>, <class 'torch.FloatTensor'>, <type 'numpy.float64'>, <class 'torch.FloatTensor'>, <type 'bool'>]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cat received an invalid combination of arguments - got (list, dim=int), but expected one of:\n * (sequence[torch.FloatTensor] seq)\n * (sequence[torch.FloatTensor] seq, int dim)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m, \u001b[32;1mdim=int\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b2357eda5233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                         for reward, value, done in zip(reward_batch,value_batch.split(1),done_batch)]\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m#print y_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;31m#y_batch = Variable(torch.from_numpy(np.resize(y_batch,[BATCH_SIZE,1])).float(),requires_grad=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cat received an invalid combination of arguments - got (list, dim=int), but expected one of:\n * (sequence[torch.FloatTensor] seq)\n * (sequence[torch.FloatTensor] seq, int dim)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m, \u001b[32;1mdim=int\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "env = filter_env.makeFilteredEnv(gym.make(ENV_NAME))\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim =  env.action_space.shape[0]\n",
    "\n",
    "net = ActorCriticNet(state_dim,action_dim)\n",
    "target_net = copy.deepcopy(net)\n",
    "memory = ReplayBuffer(REPLAY_BUFFER_SIZE)\n",
    "noise = OUNoise(action_dim)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "target_optim = optim.Optimizer(target_net.parameters(), {}) # to iterate over target params\n",
    "\n",
    "for episode in xrange(EPISODES):\n",
    "\n",
    "    print 'Episode', episode\n",
    "\n",
    "    net.train()\n",
    "    target_net.train() # not really necessary?\n",
    "\n",
    "    state = torch.from_numpy(env.reset().reshape(1,state_dim)).float()\n",
    "    noise.reset()\n",
    "\n",
    "    # Train\n",
    "    for step in xrange(env.spec.timestep_limit):\n",
    "\n",
    "        # Take noisy action - for exploration\n",
    "        action = net.getAction(Variable(state)).data + torch.from_numpy(noise.noise()).float()\n",
    "        print step, 'a', type(action)\n",
    "        new_state, reward, done, _ = env.step(action.numpy().reshape((action_dim,)))\n",
    "        \n",
    "        new_state = torch.from_numpy(new_state.reshape(1,state_dim)).float()\n",
    "        print step, 's', type(new_state)\n",
    "        \n",
    "        memory.add(state,action,reward,new_state,done)\n",
    "        if memory.count() > REPLAY_START_SIZE:\n",
    "            minibatch = memory.get_batch(BATCH_SIZE)\n",
    "            print map(type, minibatch[0])\n",
    "            state_batch = torch.cat([data[0] for data in minibatch],dim=0)\n",
    "            action_batch = torch.cat([data[1] for data in minibatch],dim=0)\n",
    "            reward_batch = np.asarray([data[2] for data in minibatch])\n",
    "            next_state_batch = torch.cat([data[3] for data in minibatch])\n",
    "            done_batch = np.asarray([data[4] for data in minibatch])\n",
    "\n",
    "            # resize action_batch (?)\n",
    "            #action_batch = action_batch.view([BATCH_SIZE,action_dim])\n",
    "\n",
    "            next_action_batch = target_net.getAction(Variable(next_state_batch))\n",
    "            value_batch = target_net.getValue(Variable(next_state_batch), next_action_batch)\n",
    "\n",
    "            # calculate y_batch - using targets\n",
    "            #next_action_batch, value_batch = zip(*[target_net(Variable(next_state)) for next_state in next_state_batch])\n",
    "            y_batch = [reward + GAMMA * value if not done else Tensor(reward)\n",
    "                        for reward, value, done in zip(reward_batch,value_batch.split(1),done_batch)]\n",
    "            #print y_batch\n",
    "            y_batch = torch.cat(y_batch,dim=0)\n",
    "            #y_batch = Variable(torch.from_numpy(np.resize(y_batch,[BATCH_SIZE,1])).float(),requires_grad=False)\n",
    "\n",
    "            # optimize net 1 step\n",
    "            #print state_batch\n",
    "            loss = criterion(net(Variable(state_batch))[1], y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update targets - using exponential moving averages\n",
    "            for group, target_group in zip(optimizer.param_groups, target_optim.param_groups):\n",
    "                for param, target_param in zip(group['params'], target_group['params']):\n",
    "                    target_param.data.mul_(1 - TAU)\n",
    "                    target_param.data.add_(TAU, param.data)\n",
    "\n",
    "        state = new_state\n",
    "        if done: break\n",
    "\n",
    "    print '- training complete', step\n",
    "\n",
    "    # Test\n",
    "    if episode % 100 == 0 and episode > 100:\n",
    "        net.eval() # set to eval - important for batch normalization\n",
    "        total_reward = 0\n",
    "        for i in xrange(TEST):\n",
    "            state = env.reset()\n",
    "            for j in xrange(env.spec.timestep_limit):\n",
    "                #env.render()\n",
    "                action = net.getAction(state) # direct action for test\n",
    "                state, reward, done, _ = env.step(action)\n",
    "                total_reward += reward\n",
    "                if done: break\n",
    "        ave_reward = total_reward / TEST\n",
    "        print '\\tTesting: Evaluation Average Reward:', ave_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
